{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a943b8-956f-4479-9a1d-ba7e8bf6c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c09e4e-aa7a-445e-a4c8-643755720436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede81cfe-780a-41c5-9b8f-249471da9daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    activation=\"swish\",\n",
    "                                    kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943add28-2acc-44d3-bed7-ee4bbd4f6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676393dc-6449-4d00-ab31-7df480e9acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5dbb94-6745-442b-8794-5a7d82cae6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc86ae44-64ea-4793-8e54-d3ceb9a0a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model.keras\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53fe0fec-5a2a-458d-9b69-89e9b0212e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27556), started 1:38:22 ago. (Use '!kill 27556' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e4931bf517820e60\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e4931bf517820e60\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8d64bd-4ab9-4445-b9db-5ef3457e0134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.1255 - loss: 11.6946 - val_accuracy: 0.1876 - val_loss: 2.2823\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1987 - loss: 2.2288 - val_accuracy: 0.2644 - val_loss: 2.0222\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.2584 - loss: 2.0217 - val_accuracy: 0.2886 - val_loss: 1.9434\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.2979 - loss: 1.9305 - val_accuracy: 0.3256 - val_loss: 1.8470\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3193 - loss: 1.8726 - val_accuracy: 0.3352 - val_loss: 1.8206\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3391 - loss: 1.8249 - val_accuracy: 0.3498 - val_loss: 1.8010\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3503 - loss: 1.7771 - val_accuracy: 0.3730 - val_loss: 1.7365\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 1.7314 - val_accuracy: 0.3796 - val_loss: 1.7078\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3850 - loss: 1.7012 - val_accuracy: 0.3866 - val_loss: 1.6914\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3955 - loss: 1.6686 - val_accuracy: 0.3948 - val_loss: 1.6756\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4058 - loss: 1.6411 - val_accuracy: 0.4084 - val_loss: 1.6464\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4164 - loss: 1.6207 - val_accuracy: 0.3898 - val_loss: 1.6747\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4246 - loss: 1.5966 - val_accuracy: 0.4118 - val_loss: 1.6369\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4315 - loss: 1.5805 - val_accuracy: 0.4180 - val_loss: 1.6309\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4413 - loss: 1.5600 - val_accuracy: 0.4260 - val_loss: 1.6099\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4453 - loss: 1.5414 - val_accuracy: 0.4210 - val_loss: 1.6173\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4531 - loss: 1.5272 - val_accuracy: 0.4304 - val_loss: 1.6008\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4569 - loss: 1.5096 - val_accuracy: 0.4300 - val_loss: 1.5959\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4630 - loss: 1.4980 - val_accuracy: 0.4332 - val_loss: 1.5978\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.4686 - loss: 1.4846 - val_accuracy: 0.4260 - val_loss: 1.6025\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.4727 - loss: 1.4742 - val_accuracy: 0.4352 - val_loss: 1.6066\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4805 - loss: 1.4538 - val_accuracy: 0.4348 - val_loss: 1.6046\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4839 - loss: 1.4466 - val_accuracy: 0.4394 - val_loss: 1.6200\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4906 - loss: 1.4360 - val_accuracy: 0.4364 - val_loss: 1.5991\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4933 - loss: 1.4233 - val_accuracy: 0.4346 - val_loss: 1.6091\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4973 - loss: 1.4132 - val_accuracy: 0.4416 - val_loss: 1.6089\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5024 - loss: 1.3996 - val_accuracy: 0.4494 - val_loss: 1.6013\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5030 - loss: 1.3910 - val_accuracy: 0.4432 - val_loss: 1.6144\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5083 - loss: 1.3816 - val_accuracy: 0.4382 - val_loss: 1.6175\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5118 - loss: 1.3707 - val_accuracy: 0.4484 - val_loss: 1.6086\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5137 - loss: 1.3639 - val_accuracy: 0.4496 - val_loss: 1.5977\n",
      "Epoch 32/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5201 - loss: 1.3507 - val_accuracy: 0.4442 - val_loss: 1.6000\n",
      "Epoch 33/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5217 - loss: 1.3414 - val_accuracy: 0.4442 - val_loss: 1.6033\n",
      "Epoch 34/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5272 - loss: 1.3349 - val_accuracy: 0.4426 - val_loss: 1.6206\n",
      "Epoch 35/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5287 - loss: 1.3256 - val_accuracy: 0.4456 - val_loss: 1.6142\n",
      "Epoch 36/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5295 - loss: 1.3197 - val_accuracy: 0.4450 - val_loss: 1.6243\n",
      "Epoch 37/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5315 - loss: 1.3132 - val_accuracy: 0.4472 - val_loss: 1.6255\n",
      "Epoch 38/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5362 - loss: 1.2996 - val_accuracy: 0.4458 - val_loss: 1.6348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x216e92ac920>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "194226c6-799a-4f3a-9d56-7801b08352a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27556), started 1:45:46 ago. (Use '!kill 27556' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-56da895d39aab476\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-56da895d39aab476\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_cifar10_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ef1ec80-08f4-4b7c-b954-2bb9b1f4102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4252 - loss: 1.6038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5958627462387085, 0.4300000071525574]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7880e35-ae3e-46ba-9954-4a6e1e598808",
   "metadata": {},
   "source": [
    "## c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab301af-f89f-4cd0-987f-6469db27b053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.1821 - loss: 2.2248 - val_accuracy: 0.2874 - val_loss: 1.9868\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.3329 - loss: 1.8359 - val_accuracy: 0.3592 - val_loss: 1.8048\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.3889 - loss: 1.7027 - val_accuracy: 0.3724 - val_loss: 1.7398\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.4261 - loss: 1.6092 - val_accuracy: 0.3494 - val_loss: 1.8391\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.4565 - loss: 1.5340 - val_accuracy: 0.3740 - val_loss: 1.7621\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.4853 - loss: 1.4588 - val_accuracy: 0.3482 - val_loss: 1.8552\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5106 - loss: 1.3887 - val_accuracy: 0.3930 - val_loss: 1.7544\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5338 - loss: 1.3257 - val_accuracy: 0.3930 - val_loss: 1.8241\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5527 - loss: 1.2782 - val_accuracy: 0.4110 - val_loss: 1.7522\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5680 - loss: 1.2266 - val_accuracy: 0.4114 - val_loss: 1.7875\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5867 - loss: 1.1805 - val_accuracy: 0.3830 - val_loss: 1.9599\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.5964 - loss: 1.1545 - val_accuracy: 0.4172 - val_loss: 1.8089\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.6170 - loss: 1.0997 - val_accuracy: 0.4138 - val_loss: 1.9084\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.6301 - loss: 1.0653 - val_accuracy: 0.4052 - val_loss: 1.9236\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.6446 - loss: 1.0278 - val_accuracy: 0.3988 - val_loss: 2.1094\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.6517 - loss: 0.9946 - val_accuracy: 0.3886 - val_loss: 2.2338\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.6674 - loss: 0.9613 - val_accuracy: 0.3942 - val_loss: 2.2653\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.6820 - loss: 0.9281 - val_accuracy: 0.4066 - val_loss: 2.1111\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.6896 - loss: 0.8916 - val_accuracy: 0.3908 - val_loss: 2.3042\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.6991 - loss: 0.8648 - val_accuracy: 0.4196 - val_loss: 2.1240\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.7082 - loss: 0.8403 - val_accuracy: 0.4028 - val_loss: 2.1925\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.7150 - loss: 0.8229 - val_accuracy: 0.4056 - val_loss: 2.1755\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.7282 - loss: 0.7844 - val_accuracy: 0.4054 - val_loss: 2.2700\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3672 - loss: 1.7353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.739780306816101, 0.3723999857902527]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_on_model.keras\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_bn_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea011f-032a-4db9-895a-403af31f7d2c",
   "metadata": {},
   "source": [
    "## d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bec22d3-dbdf-4b16-9ea8-97f5faa8ee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2744 - loss: 2.0384 - val_accuracy: 0.3814 - val_loss: 1.7553\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3849 - loss: 1.7254 - val_accuracy: 0.3890 - val_loss: 1.7379\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4288 - loss: 1.6220 - val_accuracy: 0.4264 - val_loss: 1.6501\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4514 - loss: 1.5580 - val_accuracy: 0.4486 - val_loss: 1.5788\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4816 - loss: 1.5012 - val_accuracy: 0.4544 - val_loss: 1.6080\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.4938 - loss: 1.4574 - val_accuracy: 0.4664 - val_loss: 1.6029\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5096 - loss: 1.4188 - val_accuracy: 0.4800 - val_loss: 1.5747\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5243 - loss: 1.3820 - val_accuracy: 0.4706 - val_loss: 1.5588\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5303 - loss: 1.3595 - val_accuracy: 0.4764 - val_loss: 1.5573\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5462 - loss: 1.3215 - val_accuracy: 0.4788 - val_loss: 1.5416\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5554 - loss: 1.2931 - val_accuracy: 0.4870 - val_loss: 1.5452\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5677 - loss: 1.2649 - val_accuracy: 0.4906 - val_loss: 1.5276\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5788 - loss: 1.2364 - val_accuracy: 0.4942 - val_loss: 1.5682\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5807 - loss: 1.2342 - val_accuracy: 0.4944 - val_loss: 1.5635\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5904 - loss: 1.2045 - val_accuracy: 0.4840 - val_loss: 1.6048\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6016 - loss: 1.1776 - val_accuracy: 0.4960 - val_loss: 1.5425\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6044 - loss: 1.1634 - val_accuracy: 0.4922 - val_loss: 1.5629\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6137 - loss: 1.1362 - val_accuracy: 0.4826 - val_loss: 1.5649\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6128 - loss: 1.1349 - val_accuracy: 0.4956 - val_loss: 1.5600\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6228 - loss: 1.1117 - val_accuracy: 0.4926 - val_loss: 1.6354\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6278 - loss: 1.1043 - val_accuracy: 0.5026 - val_loss: 1.5797\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6342 - loss: 1.0808 - val_accuracy: 0.4968 - val_loss: 1.6505\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6444 - loss: 1.0566 - val_accuracy: 0.5018 - val_loss: 1.5845\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6417 - loss: 1.0545 - val_accuracy: 0.4962 - val_loss: 1.6337\n",
      "Epoch 25/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6528 - loss: 1.0311 - val_accuracy: 0.4996 - val_loss: 1.6494\n",
      "Epoch 26/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 1.0163 - val_accuracy: 0.4908 - val_loss: 1.7144\n",
      "Epoch 27/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6639 - loss: 1.0021 - val_accuracy: 0.4908 - val_loss: 1.7025\n",
      "Epoch 28/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6704 - loss: 0.9837 - val_accuracy: 0.5034 - val_loss: 1.6652\n",
      "Epoch 29/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 0.9713 - val_accuracy: 0.4968 - val_loss: 1.6554\n",
      "Epoch 30/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6753 - loss: 0.9689 - val_accuracy: 0.4878 - val_loss: 1.6922\n",
      "Epoch 31/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6783 - loss: 0.9614 - val_accuracy: 0.4936 - val_loss: 1.6336\n",
      "Epoch 32/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6872 - loss: 0.9362 - val_accuracy: 0.5028 - val_loss: 1.7132\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4968 - loss: 1.5289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5276424884796143, 0.49059998989105225]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_selu_model.keras\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_selu_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998e6ff-d1e8-4433-8c28-ee7ede6f94dd",
   "metadata": {},
   "source": [
    "## e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd7c4d28-db37-48fa-9f43-5b64acdd9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be108267-7e03-48d6-88c7-ed9e0f229b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2748 - loss: 2.0674 - val_accuracy: 0.3986 - val_loss: 1.6950\n",
      "Epoch 2/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4028 - loss: 1.6899 - val_accuracy: 0.4296 - val_loss: 1.6410\n",
      "Epoch 3/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4416 - loss: 1.5920 - val_accuracy: 0.4490 - val_loss: 1.6611\n",
      "Epoch 4/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4720 - loss: 1.5163 - val_accuracy: 0.4602 - val_loss: 1.5915\n",
      "Epoch 5/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4896 - loss: 1.4530 - val_accuracy: 0.4656 - val_loss: 1.6265\n",
      "Epoch 6/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5144 - loss: 1.4046 - val_accuracy: 0.4756 - val_loss: 1.6133\n",
      "Epoch 7/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5279 - loss: 1.3634 - val_accuracy: 0.4812 - val_loss: 1.6228\n",
      "Epoch 8/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5434 - loss: 1.3195 - val_accuracy: 0.4866 - val_loss: 1.6154\n",
      "Epoch 9/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5566 - loss: 1.2795 - val_accuracy: 0.4916 - val_loss: 1.5944\n",
      "Epoch 10/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5684 - loss: 1.2487 - val_accuracy: 0.4904 - val_loss: 1.6047\n",
      "Epoch 11/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5754 - loss: 1.2196 - val_accuracy: 0.5056 - val_loss: 1.6023\n",
      "Epoch 12/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.5935 - loss: 1.1843 - val_accuracy: 0.4994 - val_loss: 1.6664\n",
      "Epoch 13/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6029 - loss: 1.1574 - val_accuracy: 0.4882 - val_loss: 1.7112\n",
      "Epoch 14/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6129 - loss: 1.1319 - val_accuracy: 0.4954 - val_loss: 1.6844\n",
      "Epoch 15/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6237 - loss: 1.1071 - val_accuracy: 0.5018 - val_loss: 1.6515\n",
      "Epoch 16/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6289 - loss: 1.0912 - val_accuracy: 0.4954 - val_loss: 1.7281\n",
      "Epoch 17/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6321 - loss: 1.0720 - val_accuracy: 0.5070 - val_loss: 1.7202\n",
      "Epoch 18/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6412 - loss: 1.0576 - val_accuracy: 0.5034 - val_loss: 1.7046\n",
      "Epoch 19/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 1.0327 - val_accuracy: 0.4980 - val_loss: 1.8216\n",
      "Epoch 20/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6611 - loss: 1.0089 - val_accuracy: 0.5054 - val_loss: 1.8284\n",
      "Epoch 21/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6643 - loss: 0.9934 - val_accuracy: 0.4934 - val_loss: 1.8280\n",
      "Epoch 22/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6736 - loss: 0.9709 - val_accuracy: 0.4916 - val_loss: 1.8652\n",
      "Epoch 23/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6797 - loss: 0.9684 - val_accuracy: 0.4950 - val_loss: 1.8800\n",
      "Epoch 24/100\n",
      "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6823 - loss: 0.9447 - val_accuracy: 0.4856 - val_loss: 1.9110\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4594 - loss: 1.6003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.59147310256958, 0.4602000117301941]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_alpha_dropout_model.keras\", save_best_only=True)\n",
    "run_index = 1\n",
    "run_logdir = Path()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51614ea6-b634-446a-b091-34f0783bdaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff9339c5-145a-4761-80d0-58dcf9fba8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = tf.keras.Sequential([\n",
    "    (\n",
    "        MCAlphaDropout(layer.rate)\n",
    "        if isinstance(layer, keras.layers.AlphaDropout)\n",
    "        else layer\n",
    "    )\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11e38799-b1c1-4c0a-bc0c-985227566773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return Y_probas.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a577fa19-3352-4ca7-8fc4-f3393eb4922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4602"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = (y_pred == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "429047b2-0a70-4d7d-b572-2b6cf7493928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d4ea533-dbb8-43fd-b4fd-2dc41bf2cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.sum_of_epoch_losses = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        mean_epoch_loss = logs[\"loss\"]  # the epoch's mean loss so far \n",
    "        new_sum_of_epoch_losses = mean_epoch_loss * (batch + 1)\n",
    "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
    "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
    "        lr = self.model.optimizer.learning_rate.numpy()\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(batch_loss)\n",
    "        self.model.optimizer.learning_rate = lr * self.factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b41be53-b54a-4ae7-b129-786d278a1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "import math\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-4,\n",
    "                       max_rate=1):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = (max_rate / min_rate) ** (1 / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    model.optimizer.learning_rate = min_rate\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    model.optimizer.learning_rate = init_lr\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee545196-425f-4749-b87f-5f080f17bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses, \"b\")\n",
    "    plt.gca().set_xscale('log')\n",
    "    max_loss = losses[0] + min(losses)\n",
    "    plt.hlines(min(losses), min(rates), max(rates), color=\"k\")\n",
    "    plt.axis([min(rates), max(rates), 0, max_loss])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32aa39be-afbc-4dd6-828b-9cdbd02dd90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1506 - loss: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1,\n",
    "                                   batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8fb77f72-1d4c-4dcb-8f1f-3e62b6fd8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=2e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe8c3c77-1d3c-4640-8ae3-7f851628bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_lr=1e-3, start_lr=None,\n",
    "                 last_iterations=None, last_lr=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr,\n",
    "                                   self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                   self.max_lr, self.start_lr)\n",
    "        else:\n",
    "            lr = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                   self.start_lr, self.last_lr)\n",
    "        self.iteration += 1\n",
    "        self.model.optimizer.learning_rate = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59575fc0-59d0-42d2-95a6-e23183a45141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2301 - loss: 2.2408 - val_accuracy: 0.3762 - val_loss: 1.7863\n",
      "Epoch 2/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3632 - loss: 1.8014 - val_accuracy: 0.4124 - val_loss: 1.6835\n",
      "Epoch 3/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4129 - loss: 1.6464 - val_accuracy: 0.4304 - val_loss: 1.6594\n",
      "Epoch 4/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4489 - loss: 1.5612 - val_accuracy: 0.4266 - val_loss: 1.7297\n",
      "Epoch 5/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4646 - loss: 1.5088 - val_accuracy: 0.4476 - val_loss: 1.6933\n",
      "Epoch 6/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4788 - loss: 1.4601 - val_accuracy: 0.4366 - val_loss: 1.8246\n",
      "Epoch 7/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4936 - loss: 1.4267 - val_accuracy: 0.4542 - val_loss: 1.7479\n",
      "Epoch 8/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5160 - loss: 1.3607 - val_accuracy: 0.4784 - val_loss: 1.6357\n",
      "Epoch 9/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5449 - loss: 1.2765 - val_accuracy: 0.4906 - val_loss: 1.6407\n",
      "Epoch 10/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5700 - loss: 1.2044 - val_accuracy: 0.4984 - val_loss: 1.6032\n",
      "Epoch 11/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5941 - loss: 1.1342 - val_accuracy: 0.5178 - val_loss: 1.5881\n",
      "Epoch 12/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6205 - loss: 1.0660 - val_accuracy: 0.5162 - val_loss: 1.6143\n",
      "Epoch 13/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6391 - loss: 1.0056 - val_accuracy: 0.5148 - val_loss: 1.6209\n",
      "Epoch 14/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6560 - loss: 0.9557 - val_accuracy: 0.5174 - val_loss: 1.6111\n",
      "Epoch 15/15\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6676 - loss: 0.9254 - val_accuracy: 0.5194 - val_loss: 1.5932\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "n_iterations = math.ceil(len(X_train_scaled) / batch_size) * n_epochs\n",
    "onecycle = OneCycleScheduler(n_iterations, max_lr=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13d06fc2-d0e5-4f98-96fc-e5a6e0d62588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5065 - loss: 1.6056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6145617961883545, 0.5078999996185303]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98065c61-b4ab-4c3f-834d-b39d2e547a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
